{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e56ef88",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb841026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os,random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump,load\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,Dense,Embedding,GRU,Input,Conv2D,MaxPool2D,Dropout,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f01a6",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc45d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocabSize,seqLength):\n",
    "    encoderInput = Input(shape=(None,),name='encoderInput')\n",
    "    net = Embedding(vocabSize,seqLength)(encoderInput)\n",
    "    net = Bidirectional(LSTM(250,return_sequences=True))(net)\n",
    "    net = Bidirectional(LSTM(250,return_sequences=True))(net)\n",
    "    net = Bidirectional(LSTM(250,return_sequences=False))(net)\n",
    "    net = Dense(250,activation='tanh')(net)\n",
    "    encoderOutput = net\n",
    "    return encoderInput,encoderOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30eb4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(initState,vocabSize,seqLength):\n",
    "    decoderInput = Input(shape=(None,),name='decoderInput')\n",
    "    net = Embedding(vocabSize,seqLength)(decoderInput)\n",
    "    net = GRU(250,return_sequences=True)(net,initial_state=initState)\n",
    "    net = GRU(250,return_sequences=True)(net,initial_state=initState)\n",
    "    net = GRU(250,return_sequences=True)(net,initial_state=initState)\n",
    "    net = Dropout(0.1)(net)\n",
    "    net = Dense(vocabSize,activation='softmax',name='decoderOutput')(net)\n",
    "    decoderOutput = net\n",
    "    return decoderInput,decoderOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79b49f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede7498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830068b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6147410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start,end = '<start>','<end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5efaf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wordNumber.csv')[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af7100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nums</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8050006</td>\n",
       "      <td>eight million, fifty thousand and six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>75515</td>\n",
       "      <td>seventy-five thousand, five hundred and fifteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9285557</td>\n",
       "      <td>nine million, two hundred and eighty-five thou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>606467</td>\n",
       "      <td>six hundred and six thousand, four hundred and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>268340</td>\n",
       "      <td>two hundred and sixty-eight thousand, three hu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     nums                                              words\n",
       "0           0  8050006              eight million, fifty thousand and six\n",
       "1           1    75515    seventy-five thousand, five hundred and fifteen\n",
       "2           2  9285557  nine million, two hundred and eighty-five thou...\n",
       "3           3   606467  six hundred and six thousand, four hundred and...\n",
       "4           4   268340  two hundred and sixty-eight thousand, three hu..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb8274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers,words = data.nums,data.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d4556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [[char for char in str(word)] for word in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600550cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8', '0', '5', '0', '0', '0', '6']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c68fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [[start] + [str(char) for char in nlp(word)] + [end] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df95e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>',\n",
       "  'eight',\n",
       "  'million',\n",
       "  ',',\n",
       "  'fifty',\n",
       "  'thousand',\n",
       "  'and',\n",
       "  'six',\n",
       "  '<end>'],\n",
       " ['<start>',\n",
       "  'seventy',\n",
       "  '-',\n",
       "  'five',\n",
       "  'thousand',\n",
       "  ',',\n",
       "  'five',\n",
       "  'hundred',\n",
       "  'and',\n",
       "  'fifteen',\n",
       "  '<end>']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e370659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(numbers + words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afcce17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabLength = len(tokenizer.word_index) + 1\n",
    "seqLength = vocabLength "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a18af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'hundred': 2,\n",
       " ',': 3,\n",
       " '-': 4,\n",
       " '<start>': 5,\n",
       " '<end>': 6,\n",
       " 'thousand': 7,\n",
       " 'million': 8,\n",
       " '3': 9,\n",
       " '6': 10,\n",
       " '2': 11,\n",
       " '5': 12,\n",
       " '1': 13,\n",
       " '4': 14,\n",
       " '9': 15,\n",
       " '7': 16,\n",
       " '8': 17,\n",
       " '0': 18,\n",
       " 'one': 19,\n",
       " 'five': 20,\n",
       " 'six': 21,\n",
       " 'three': 22,\n",
       " 'two': 23,\n",
       " 'seven': 24,\n",
       " 'four': 25,\n",
       " 'nine': 26,\n",
       " 'eight': 27,\n",
       " 'thirty': 28,\n",
       " 'sixty': 29,\n",
       " 'twenty': 30,\n",
       " 'fifty': 31,\n",
       " 'eighty': 32,\n",
       " 'forty': 33,\n",
       " 'ninety': 34,\n",
       " 'seventy': 35,\n",
       " 'twelve': 36,\n",
       " 'fifteen': 37,\n",
       " 'ten': 38,\n",
       " 'eleven': 39,\n",
       " 'nineteen': 40,\n",
       " 'sixteen': 41,\n",
       " 'thirteen': 42,\n",
       " 'fourteen': 43,\n",
       " 'eighteen': 44,\n",
       " 'seventeen': 45}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00156d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b64a0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderInputData = tokenizer.texts_to_sequences(numbers)\n",
    "decoderInputData = tokenizer.texts_to_sequences([i[:-1] for i in words])\n",
    "decoderOuputData = tokenizer.texts_to_sequences([i[1:] for i in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ab4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderInputData = pad_sequences(numbers,maxlen=vocabLength,padding='post')\n",
    "decoderInputData = pad_sequences(decoderInputData,maxlen=vocabLength,padding='post')\n",
    "decoderOutputData = pad_sequences(decoderOuputData,maxlen=vocabLength,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be08e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "del words\n",
    "del numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "393ef3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  8,  3, ...,  0,  0,  0],\n",
       "       [35,  4, 20, ...,  0,  0,  0],\n",
       "       [26,  8,  3, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [24,  8,  3, ...,  0,  0,  0],\n",
       "       [23,  2,  1, ...,  0,  0,  0],\n",
       "       [27,  8,  3, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderOutputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46767ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xFeatures = {\n",
    "    'encoderInput': encoderInputData,\n",
    "    'decoderInput': decoderInputData\n",
    "}\n",
    "yLabels = {\n",
    "    'decoderOutput': to_categorical(decoderOutputData,num_classes=vocabLength)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accef7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del encoderInputData\n",
    "# del decoderInputData\n",
    "# del decoderOuputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64f19cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderInput,encoderOutput = encoder(vocabLength,seqLength)\n",
    "# encoderModel = Model(inputs=[encoderInput],\n",
    "#                     outputs=[encoderOutput])\n",
    "decoderInitialState = encoderOutput\n",
    "# encoderModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2304c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderInput,decoderOutput = decoder(decoderInitialState,vocabLength,seqLength)\n",
    "# decoderModel = Model(inputs=[decoderInput],\n",
    "#                     outputs=[decoderOutput])\n",
    "# decoderModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68710495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoderInput,decoderInput],\n",
    "                    outputs=[decoderOutput])\n",
    "model.compile(\n",
    "             optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd905870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 621s 2s/step - loss: 0.6689 - accuracy: 0.8152\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 2496s 8s/step - loss: 0.3613 - accuracy: 0.8749\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 599s 2s/step - loss: 0.2929 - accuracy: 0.9030\n",
      "Epoch 4/5\n",
      " 52/313 [===>..........................] - ETA: 8:18 - loss: 0.2495 - accuracy: 0.9185"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "          xFeatures,\n",
    "          yLabels,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          verbose=True,\n",
    "          workers=-1,\n",
    "          use_multiprocessing=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6634b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xFeatures,yLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fe35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = random.randint(0,len(xFeatures2['encoderInput']))\n",
    "# image = xFeatures2['encoderInput'][idx]\n",
    "# image = np.expand_dims(image,axis=0)\n",
    "# dinput = tokenizer.texts_to_sequences([[startSeq]])\n",
    "# dinput = pad_sequences(dinput,maxlen=vocabLength,padding='post',dtype='float32')\n",
    "# # print(dinput)\n",
    "# # calcPred = encoderModel.predict(image)\n",
    "# # for i in calcPred:\n",
    "# #     print(np.argmax(i))\n",
    "# #\n",
    "# x = {\n",
    "#     'encoderInput':image,\n",
    "#     'decoderInput':dinput\n",
    "# }\n",
    "# # initialState = encoderModel.predict(calc)\n",
    "# prediction = model.predict(x,verbose=False)\n",
    "# # #\n",
    "# results = ''\n",
    "# for pred in prediction:\n",
    "#     for i in pred: \n",
    "#         index = np.argmax(i)\n",
    "#         result = tokenizer.index_word[index] if index != 0 else ''\n",
    "#         results += result\n",
    "# print('prediction:',results)\n",
    "# print('image : ')\n",
    "# plt.imshow(image[0]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
